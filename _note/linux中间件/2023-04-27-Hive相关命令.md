---
layout: post
title: Hive相关命令
lead: 
categories: 
  - note
---

- toc
{: toc }


## HIVE 删除分区表，但是对应的分区目录还在

### 问题现象：在hive的分区表中删除了分区，命令执行返回成功，但是hdfs上对应的分区目录却没有删除。

执行删除分区的操作，命令返回成功，元数据中也不存在该分区。

```js
hive>  alter table  default.logs drop partition (dt="2022",country="guangzhou") ;
OK
Time taken: 0.052 seconds
hive> show partitions default.logs ;
OK
dt=2022/country=beijing
dt=2022/country=wuhan
```

查看对应的目录，发现分区dt=2022/country=guangzhou并没有删除掉，正常情况下分区目录是会被删除的。

```js
hadoop fs -ls    /usr/hive/warehouse/logs/dt=2022/
Found 3 items
drwxr-xr-x   - hadoop supergroup          0 2022-12-06 19:17 /usr/hive/warehouse/logs/dt=2022/country=beijing
drwxr-xr-x   - hadoop supergroup          0 2022-12-06 20:02 /usr/hive/warehouse/logs/dt=2022/country=guangzhou
drwxr-xr-x   - hadoop supergroup          0 2022-12-06 19:14 /usr/hive/warehouse/logs/dt=2022/country=wuhan
```

问题原因：**要删除的分区目录不在元数据中。**因为要删除的分区目录dt=2022/country=guangzhou是其他程序拉取数据生成的，正常情况下，生产数据后是要进行元数据同步（msck repair table  表名 ;），但是该分区目录生成后没有进行分区修复操作来同步元数据。导致元数据中并没有该目录的路径对应的分区，所以删除该分区时候无法删除掉该目录。

### 解决方案：修复分区同步元数据，再删除该目录。

> msck repair table  {表名}

```js
hive>  msck repair table default.logs ;
OK
Partitions not in metastore:    logs:dt=2022/country=guangzhou
Repair: Added partition to metastore logs:dt=2022/country=guangzhou
Time taken: 0.07 seconds, Fetched: 2 row(s)
hive>  alter table  default.logs drop partition (dt="2022",country="guangzhou") ;
Dropped the partition dt=2022/country=guangzhou
OK
Time taken: 0.078 seconds
```

此时，对应的分区目录被删除

```shell
[hadoop@172 ~]$ hadoop fs -ls /usr/hive/warehouse/logs/dt=2022/
Found 2 items
drwxr-xr-x   - hadoop supergroup          0 2022-12-06 19:17 /usr/hive/warehouse/logs/dt=2022/country=beijing
drwxr-xr-x   - hadoop supergroup          0 2022-12-06 19:14 /usr/hive/warehouse/logs/dt=2022/country=wuhan
```





## 命令汇总

### 同步元数据

```sql
msck repair table {表名};
```



### 查看表所有分区

```sql
show partitions {表名};
```





### 删除表分区

```sql
alter table {表名} drop partition ({分区字段1}={分区值1},{分区字段2}={分区值2});
```



### Hadoop 清空回收站

1. 清空回收站命令：

```shell
hdfs dfs -expunge
```

2. 删除.Trash目录（清理垃圾）

```shell 
hadoop fs -rmr -skipTrash /user/$USER/.Trash
```


注意：需要添加参数： -skipTrash 才会完全删除，如果不添加，会放到另外一个.Trash



