---
layout: post
title: Apache Kudu 读写异常问题修复 & 总结
description: Apache Kudu 读写异常问题修复 & 总结
lead: 
comments: true
categories: bigdata
tags:
    - kudu
    - production
---

## 现象

2023-05-15 10:30 

StreamSet (后文简写sdc) 服务开始告警， 跟kudu写入相关的部分pipline开始出现了异常。

DolphinScheduler 部分任务出现了异常告警。

应用服务部分接口也出现了超时。

...



由此，一个美好的周末，就此变得逐渐糟糕 ( 暴躁 #x#）.



## 排查

### 初次尝试 - SDC，Impala

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/异常1.png )

最开始只发现sdc pipline异常, 看报文提示为 rpc 通信失败, 怀疑是sdc服务异常, 于是尝试重启sdc. but! 可惜的是重试后异常依旧..

后面发现impala 读写kudu表时同样存在响应超时，看到这，犯罪目标逐渐清晰,  没错，该出来挨打的就是本篇主角 - Kudu.



### 目标清晰 - Kudu

> 定位到坏小子之后，由于对kudu不太熟悉所以瞎折腾进行了一下操作， 让我们忽略它， 关注重点  (all right ^^

**kudu的集群分布**

| 节点         | master   | tablet           |
| ------------ | -------- | ---------------- |
| pro-data-001 |          | tablet-server-01 |
| pro-data-002 |          | tablet-server-02 |
| pro-data-003 | master01 | tablet-server-03 |
| pro-data-004 | master02 | tablet-server-04 |
| pro-data-005 | master03 | tablet-server-05 |

---

#### 第一个排查点

在几次重启后， 发现 tablet-server-02 节点会一直出现异常导致节点离线,  日志如下：

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/异常2.png )

于是尝试删除下线该节点，看故障节点下线后服务是否会恢复.

事实及后续操作证明了这是不可行的，这样做的结果只是把这个异常给消灭掉了， 但是kudu服务本身还是在继续摆烂 （一脸捉急 ##）

---

#### 第二个排查点

于是在重启节点无果后，开始关注问题本身  `RPC connect closed`  .

开始疯狂找相关资料，熟悉了下kudu各服务模块所承担的角色及任务功能，详细看传送门 > [博客地址](https://zhuanlan.zhihu.com/p/426901943)<.

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/异常3.png )

加上 dolphin任务调度后异常的日志， 基本可以判断是 `kudu的 tablet server` 导致的异常

| 服务角色      | http端口 | rpc端口 |
| ------------- | -------- | ------- |
| master        | 8051     | 7051    |
| tablet server | 8050     | 7050    |

---

#### 第三个排查点

到这终于有点头绪了， 就像落入大海中抓住了救生圈，本来有点萎靡的精神顿时又振奋了起来~

开始排查，首先看cdh中kudu的各服务状态，如下图

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/异常4.png )

通过它能看到的是tablet 除了我们手动停止的 `tablet-02` 节点之外, 其他节点状态都是正常的，但事实真是这样的吗？

让我们试验一下，登上堡垒机一个个telnet, 不出所料

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/异常5.png )

Tablet服务集群中的 `3`，`4`节点都在偷偷挂着摸鱼. （磨牙中）

就此问题原因大概就能猜个八九不离十了。

原因应该就是其上游服务 (impala, sdc, ...) 在与kudu通过RPC服务通信时， 由于**03,04** 节点宕机，请求连过来直接电话不在服务区，这谁受得了，导致上游服务也直接开摆了。

---



## 恢复

### 资料

好消息异常点是定位到了，但坏消息是这个问题要怎么解决呢？

好在幸运的是通过一翻互联网冲浪， 找到了两篇相关的博文. (来自前辈的关爱)

- https://blog.csdn.net/m0_37534613/article/details/96591677
- https://segmentfault.com/a/1190000021635655

(ps: 值得吐槽的是kudu的相关资料是真不好找哇，issue只能去他官网提，一开始点开github还有点懵，属实长见识。同样值得说的是文档写的确实详细，虽说在国外技术圈子文化是这样的 doge)

### 操作

通过上面两篇博客的指点，我一个任督二脉的打通，直接上操作

#### 拉取报告

```shell
sudo -u kudu kudu cluster ksck pro-data-sh003,pro-data-sh004,pro-data-sh005 > ./ksck.out 2>&1

# 命令详解
# `sudo -u kudu` 使用kudu用户执行语句
# `kudu cluster ksck` 表示使用 ksck这个工具
# `pro-data-sh003,pro-data-sh004,pro-data-sh005` 为kudu 集群的主节点机器名
# `> ./ksck.out 2>&1` 表示将结果输出至 ./ksck.out 文件
```

通过这条命令拿到kudu的健康检查报告 `ksck.out`

#### 构建修复脚本

```python
import re

# 读取文件 ksct.out
start_flag = False
process_index = 0
command_list = []
command = 'sudo -u kudu kudu remote_replica unsafe_change_config ${replica_node} ${tablet_id} ${replica_id}'

with open('ksck.out') as ksc:
    # 读取文件内容
    ksc_contents = ksc.readlines()
    for ksc_content in ksc_contents:
        # 判断内容是否匹配正则 `(Tablet (.*) of table)`
        if re.match(r'(Tablet (.*) of table)', ksc_content):
            start_flag = True
        # 只取读取文件内容的当前及后3行
        if process_index > 4:
            command = 'sudo -u kudu kudu remote_replica unsafe_change_config ${replica_node} ${tablet_id} ${replica_id}'
            start_flag = False
            process_index = 0
        # 取内容
        if start_flag:
            process_index += 1
            # 当前行, 取出 tablet_id
            if process_index == 1:
                tablet_id = re.match(r'(Tablet (.*) of table)', ksc_content).group(2)
                command = command.replace('${tablet_id}', tablet_id)
            if process_index > 1:
                # 正则匹配 `(.*) (\(pro-data-sh00[0-9]:7050\)): RUNNING`
                if re.match(r'(.*) (\(pro-data-sh00[0-9]:7050\)): RUNNING', ksc_content):
                    # 第一个捕获的为replica_id , 第二个捕获的为 replica_node
                    match_result = re.match(r'(.*) \((pro-data-sh00[0-9]:7050)\): RUNNING', ksc_content)
                    replica_id = match_result.group(1)
                    replica_node = match_result.group(2)
                    command = command.replace('${replica_id}', replica_id)
                    command = command.replace('${replica_node}', replica_node)
                    command_list.append(command)


print(command_list)
# 将command_list 写入到一个名为 fix_tablet.sh 的文件中
write_index = 0
file_index = 0
with open(file=f'./fix_tablet.sh-{file_index}.sh', mode='w', encoding='utf-8') as fix_tablet:
    fix_tablet.write('#!/bin/bash\n')
    fix_tablet.write('echo "执行开始"\n')
    # 每一百条分割一个文件
    for write_command in command_list:
        if write_index != 0 and write_index % 100 == 0:
            file_index += 1
            fix_tablet.write('echo "执行结束"\n')
            # 重新打开一个文件
            fix_tablet = open(file=f'./fix_tablet.sh-{file_index}.sh', mode='w', encoding='utf-8')
            fix_tablet.write('#!/bin/bash\n')
            fix_tablet.write('echo "执行开始"\n')

        fix_tablet.write(f'{write_command}\n')
        # linux命令暂停1秒
        fix_tablet.write(f'sleep 1\n')
        fix_tablet.write(f'echo "执行第{write_index}条"\n')
        write_index += 1
```

通过上面这个脚本将 `ksck.out` 中的错误报告拆分为修复脚本中的一条条命令, 脚本文件命名为 `fix_tablet-*.sh` (每百条分片为一个文件).

例如将 `报错信息`

```
# Tablet 4523ee9b9e5d4e67b74de1d3e6c0a7e0 of table 'impala::kudu_pro.wms_yb_iostorage_detail' is unavailable: 2 replica(s) not RUNNING
#   c29a020548d6481b81a421299262d92b: TS unavailable
#   fc47010673be46cfbe5cc58d2868b43d: TS unavailable
#   9ca534be0ca342409553acea7f5e7c1b (pro-data-sh005:7050): RUNNING [LEADER]
```

调整为语句

```shell
sudo -u kudu kudu remote_replica unsafe_change_config pro-data-sh005:7050 79e0907e251644a49cd57bb79024b4df   9ca534be0ca342409553acea7f5e7c1b

# 命令详解
# 该语句作用是对tablet的replicate节点做调整，只保留语句中所配置的replication node
# `sudo -u kudu` 使用kudu用户执行语句
# `kudu remote_replica unsafe_change_config` 使用客户端工具命令
# `pro-data-sh005:7050` 对应tablet的 `LEADER` 节点通信地址端口
# `9ca534be0ca342409553acea7f5e7c1b` 对应的replication UID
```

#### 执行脚本

然后就是苦逼的一个个执行脚本，

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/排查1.png )

直至所有脚本都执行完成后，也就代表着我们整个修复流程结束了，可以看到的现象就是pipline可以正常写入kudu, dolphin任务执行正常. (喜大普奔)



## 其他

> 上述流程中留了两个坑 (可能还不止 doge),  因为跟主流程不搭嘎, 所以就安排在这补上.

### 神奇的错误日志

没错， 说的就是在排查点1的错误日志

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/异常2.png )

重点关注这一句 `Failed to append delta: uncompressed block size 16942894 is greater than the configured maximum size 16777216`

这句话用我那蹩脚英语水平带上翻译软件直译过来就是 `未压缩块大小 16942894 大于配置的最大大小 16777216`, 唯一熟悉的是 `16777216` , 换算过来就是16m,  于是百度+摇人，得出这应该是一个配置的结论。

#### 配置项

经过一番折腾，找了一阵终于锁定到了对应配置的配置项

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/其他2.png )

该页面可通过 `teblet_node:port/varz` 访问

#### 配置调整 + 重启搞定

调整配置后， 重启该异常消失，同时`tablet server 02`节点重启也不再异常

![placeholder](/assets/images/Kudu读&写表异常问题修复&总结/其他3.png )

---

### 下线的 Tablet 02 节点

>  之前排查过程中因为 `02` 节点一直宕机，所以直接将 `02` 节点下掉了。

由于 `kudu` 表 `tablet` 对应 `replication leader` 节点都分布在 `02`，`05`节点。 在 `02` 节点下线后，在进行读操作时查询某些 `replication leader`节点在 `02` 机器上的表会查询超时，导致上游服务查询异常报错。

于是在将该节点重新上线后， 数据应用服务查询也了恢复正常 . 



## 相关资料

### 相关博文

- https://segmentfault.com/a/1190000021635655
- https://blog.csdn.net/m0_37534613/article/details/96591677
- https://www.cnblogs.com/barneywill/p/10581678.html
- https://zhuanlan.zhihu.com/p/426901943

### 官方文档

- https://kudu.apache.org/releases/1.5.0/docs

### 其他

- https://github.com/apache/kudu
- https://issues.apache.org/jira/projects/KUDU/issues